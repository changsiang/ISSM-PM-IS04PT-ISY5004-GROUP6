{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOQ-2xS_MYHi"
   },
   "source": [
    "## **i. Import the libraries**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yoi4gWDELtek",
    "outputId": "b2b7034c-89a9-484a-b106-8b3f32da44f2"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "from PIL import Image\n",
    "from threading import Thread\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iv. Judge glasses on video\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_1=cv.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector=dlib.get_frontal_face_detector()\n",
    "predictor=dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for capturing the video frames\n",
    "# This class handles the video stream \n",
    "# captured from the WebCam\n",
    "\n",
    "class VideoStream:\n",
    "    def __init__(self, stream):\n",
    "        self.video = cv.VideoCapture(stream)\n",
    "        \n",
    "        # Setting the FPS for the video stream\n",
    "        self.video.set(cv.CAP_PROP_FPS, 60)\n",
    "\n",
    "        if self.video.isOpened() is False:\n",
    "            print(\"Can't accessing the webcam stream.\")\n",
    "            exit(0)\n",
    "\n",
    "        self.grabbed , self.frame = self.video.read()\n",
    "        self.stopped = True\n",
    "        \n",
    "        # Creating a thread\n",
    "        self.thread = Thread(target=self.update)\n",
    "        self.thread.daemon = True\n",
    "    \n",
    "    def start(self):\n",
    "        self.stopped = False\n",
    "        self.thread.start()\n",
    "\n",
    "    def update(self):\n",
    "        while True :\n",
    "            if self.stopped is True :\n",
    "                break\n",
    "            self.grabbed , self.frame = self.video.read()\n",
    "        self.video.release()\n",
    "\n",
    "    def read(self):\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start capturing video frames through Webcam\n",
    "# Capturing video through the WebCam. 0 represents the\n",
    "# default camera. You need to specify another number for\n",
    "# any external camera\n",
    "\n",
    "video_stream = VideoStream(stream=0)\n",
    "video_stream.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) C:\\b\\abs_74oeeuevib\\croots\\recipe\\opencv-suite_1664548340488\\work\\modules\\imgproc\\src\\smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'cv::GaussianBlur'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 23\u001b[0m\n\u001b[0;32m     19\u001b[0m             frame_crop \u001b[38;5;241m=\u001b[39m frame[top \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m10\u001b[39m:top\u001b[38;5;241m+\u001b[39mheight\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, left \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m30\u001b[39m: \\\n\u001b[0;32m     20\u001b[0m             left\u001b[38;5;241m+\u001b[39mwidth \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m20\u001b[39m]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#            cv.imshow(\"Cropped Frame\", frame_crop)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m             img_blur \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGaussianBlur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_crop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43msigmaX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigmaY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m             edges \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mCanny(image \u001b[38;5;241m=\u001b[39mimg_blur, threshold1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, threshold2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m     25\u001b[0m             cv\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCanny Filter\u001b[39m\u001b[38;5;124m\"\u001b[39m, edges)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) C:\\b\\abs_74oeeuevib\\croots\\recipe\\opencv-suite_1664548340488\\work\\modules\\imgproc\\src\\smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'cv::GaussianBlur'\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    if video_stream.stopped is True:\n",
    "        break\n",
    "    else:\n",
    "        frame = video_stream.read()\n",
    "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    "        rects = detector(gray, 1)\n",
    "        \n",
    "        for i, face_rect in enumerate(rects):\n",
    "            left = face_rect.left() \n",
    "            top = face_rect.top()\n",
    "            width = face_rect.right() - left\n",
    "            height = face_rect.bottom() - top\n",
    "\n",
    "            cv.rectangle(frame, (left, top), (left+width, top+height), (0,255,0), 2)\n",
    "            cv.putText(frame, f\"Face {i+1}\", (left - 10, top - 10), font_1, 0.7, (0, 255, 0), 2, cv.LINE_AA)\n",
    "\n",
    "            frame_crop = frame[top + 10:top+height-100, left + 30: \\\n",
    "            left+width - 20]\n",
    "#            cv.imshow(\"Cropped Frame\", frame_crop)\n",
    "            \n",
    "            img_blur = cv.GaussianBlur(np.array(frame_crop),(3,3),sigmaX=1.7, sigmaY=1.7)\n",
    "            edges = cv.Canny(image =img_blur, threshold1=100, threshold2=200)\n",
    "            cv.imshow(\"Canny Filter\", edges)\n",
    "\n",
    "            edges_center = edges.T[(int(len(edges.T)/2))]\n",
    "            if 255 in edges_center:\n",
    "                cv.rectangle(frame, (left, top+height), (left+width,top+height+40), (0,255,0), cv.FILLED)\n",
    "                cv.putText(frame, \"Glass is Present\", (left+10,top+height+20), font_1, 0.65, (255, 255, 255), 2, cv.LINE_AA)\n",
    "            else:\n",
    "                cv.rectangle(frame, (left, top+height), (left+width,top+height+40), (0,255,0), cv.FILLED)\n",
    "                cv.putText(frame, \"No Glass\", (left+10, top+height+20),font_1, 0.65, (0, 0, 255), 2, cv.LINE_AA)\n",
    "\n",
    "        # delay for processing a frame\n",
    "        delay = 0.04\n",
    "        time.sleep(delay)\n",
    "\n",
    "    cv.imshow(\"Result\", frame)\n",
    "    \n",
    "    key = cv.waitKey(1)\n",
    "    # Press 'q' for stop the executing of the program\n",
    "    if key == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop capturing video frames and close all windows\n",
    "\n",
    "video_stream.stop()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
