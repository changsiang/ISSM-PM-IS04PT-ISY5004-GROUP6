{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":55176,"status":"ok","timestamp":1684557057788,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"},"user_tz":-480},"id":"G6EqyEN1VkNV","outputId":"c3948a3d-9bf4-4b0f-b3cb-8d409cdfd77a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following additional packages will be installed:\n","  tesseract-ocr-eng tesseract-ocr-osd\n","The following NEW packages will be installed:\n","  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n","0 upgraded, 3 newly installed, 0 to remove and 24 not upgraded.\n","Need to get 4,850 kB of archives.\n","After this operation, 16.3 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1 [1,598 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1 [2,990 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 tesseract-ocr amd64 4.1.1-2build2 [262 kB]\n","Fetched 4,850 kB in 2s (3,113 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package tesseract-ocr-eng.\n","(Reading database ... 122531 files and directories currently installed.)\n","Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1_all.deb ...\n","Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n","Selecting previously unselected package tesseract-ocr-osd.\n","Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1_all.deb ...\n","Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n","Selecting previously unselected package tesseract-ocr.\n","Preparing to unpack .../tesseract-ocr_4.1.1-2build2_amd64.deb ...\n","Unpacking tesseract-ocr (4.1.1-2build2) ...\n","Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1) ...\n","Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1) ...\n","Setting up tesseract-ocr (4.1.1-2build2) ...\n","Processing triggers for man-db (2.9.1-1) ...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytesseract\n","  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (8.4.0)\n","Installing collected packages: pytesseract\n","Successfully installed pytesseract-0.3.10\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting keras_applications\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras_applications) (1.24.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras_applications) (3.8.0)\n","Installing collected packages: keras_applications\n","Successfully installed keras_applications-1.0.8\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/ma7555/keras-vggface.git\n","  Cloning https://github.com/ma7555/keras-vggface.git to /tmp/pip-req-build-iesxjsfu\n","  Running command git clone --filter=blob:none --quiet https://github.com/ma7555/keras-vggface.git /tmp/pip-req-build-iesxjsfu\n","  Resolved https://github.com/ma7555/keras-vggface.git to commit 97a512377f9ead550a74595b657c7ec9b8161e75\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.7) (1.24.3)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.7) (1.10.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.7) (3.8.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.7) (8.4.0)\n","Requirement already satisfied: tensorflow>=2.6 in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.7) (2.12.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.7) (1.16.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.7) (6.0)\n","Requirement already satisfied: keras-applications in /usr/local/lib/python3.10/dist-packages (from keras-vggface==0.7) (1.0.8)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (1.54.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (0.3.25)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (16.0.0)\n","Collecting numpy>=1.9.1 (from keras-vggface==0.7)\n","  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (67.7.2)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (2.12.2)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.6->keras-vggface==0.7) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.6->keras-vggface==0.7) (0.40.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (2.27.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (2.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.6->keras-vggface==0.7) (3.2.2)\n","Building wheels for collected packages: keras-vggface\n","  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-vggface: filename=keras_vggface-0.7-py3-none-any.whl size=8320 sha256=ce5455398d6fe779f20d9a65bb862c9a02a902f640612d807214d1269fdc96c3\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ncweudjv/wheels/e3/b0/c4/d248c583f944c032a2429b2c0b4bfba1f24ac9c50ca6692eaf\n","Successfully built keras-vggface\n","Installing collected packages: numpy, keras-vggface\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.24.3\n","    Uninstalling numpy-1.24.3:\n","      Successfully uninstalled numpy-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.25 which is incompatible.\n","flax 0.6.9 requires jax>=0.4.2, but you have jax 0.3.25 which is incompatible.\n","orbax-checkpoint 0.2.1 requires jax>=0.4.8, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-vggface-0.7 numpy-1.23.5\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}],"source":["!sudo apt install tesseract-ocr\n","!pip install pytesseract\n","!pip install keras_applications\n","!pip install git+https://github.com/ma7555/keras-vggface.git"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"OvpNi21jNWQM","executionInfo":{"status":"ok","timestamp":1684557167943,"user_tz":-480,"elapsed":6354,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}}},"outputs":[],"source":["import cv2\n","import numpy as np\n","from google.colab.patches import cv2_imshow\n","import pytesseract as ocr\n","import dlib\n","from keras import applications, Model\n","from keras.layers import Flatten, Dense\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score\n","import math\n","from sklearn.decomposition import PCA\n","from sklearn.svm import SVC\n"]},{"cell_type":"code","source":["# use VGGFace model\n","from keras_vggface.vggface import VGGFace\n","from keras_vggface.utils import preprocess_input\n","from keras.preprocessing import image"],"metadata":{"id":"NBDxr_pDzw1P","executionInfo":{"status":"ok","timestamp":1684557171606,"user_tz":-480,"elapsed":284,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":287,"status":"ok","timestamp":1684557173151,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"},"user_tz":-480},"id":"O8mRRjdQNahg","outputId":"330370a7-5a6a-4a31-dfe9-7a5527a4e59d"},"outputs":[{"output_type":"stream","name":"stdout","text":["cv2:  4.7.0\n","numpy:  1.24.3\n","pytesseract:  0.3.10\n"]}],"source":["print(\"cv2: \", cv2.__version__)\n","print(\"numpy: \", np.__version__)\n","print(\"pytesseract: \", ocr.__version__)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2452,"status":"ok","timestamp":1684557177046,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"},"user_tz":-480},"id":"M_WQ3bgoXWvk","outputId":"d0b60afd-70a1-40dd-c059-c1a958604fff"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-05-20 04:32:54--  https://github.com/italojs/facial-landmarks-recognition/raw/master/shape_predictor_68_face_landmarks.dat\n","Resolving github.com (github.com)... 140.82.114.3\n","Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/italojs/facial-landmarks-recognition/master/shape_predictor_68_face_landmarks.dat [following]\n","--2023-05-20 04:32:54--  https://raw.githubusercontent.com/italojs/facial-landmarks-recognition/master/shape_predictor_68_face_landmarks.dat\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 99693937 (95M) [application/octet-stream]\n","Saving to: ‘shape_predictor_68_face_landmarks.dat’\n","\n","shape_predictor_68_ 100%[===================>]  95.08M   213MB/s    in 0.4s    \n","\n","2023-05-20 04:32:56 (213 MB/s) - ‘shape_predictor_68_face_landmarks.dat’ saved [99693937/99693937]\n","\n","--2023-05-20 04:32:56--  https://raw.githubusercontent.com/kipr/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1254733 (1.2M) [text/plain]\n","Saving to: ‘haarcascade_frontalface_default.xml’\n","\n","haarcascade_frontal 100%[===================>]   1.20M  --.-KB/s    in 0.05s   \n","\n","2023-05-20 04:32:56 (21.9 MB/s) - ‘haarcascade_frontalface_default.xml’ saved [1254733/1254733]\n","\n"]}],"source":["# download weights\n","\n","!wget https://github.com/italojs/facial-landmarks-recognition/raw/master/shape_predictor_68_face_landmarks.dat -O \"shape_predictor_68_face_landmarks.dat\"\n","!wget https://raw.githubusercontent.com/kipr/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml -O \"haarcascade_frontalface_default.xml\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJwquqApmWA7"},"outputs":[],"source":["# load weights\n","cascade_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n","landmarks_predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1681191940638,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"},"user_tz":-480},"id":"xB-Mp-AcNxoq","outputId":"7d8b6748-fa4d-4282-ad74-454e81d10bd4"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=350x250 at 0x7FC19C6EBAC0>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAV4AAAD6CAIAAABms7gBAAAC8klEQVR4nO3UMRHAIADAQMC/qUpAEZ17l50O/woyZZ5nD4CvdTsA+CNrAII1AMEagGANQLAGIFgDEKwBCNYABGsAgjUAwRqAYA1AsAYgWAMQrAEI1gAEawCCNQDBGoBgDUCwBiBYAxCsAQjWAARrAII1AMEagGANQLAGIFgDEKwBCNYABGsAgjUAwRqAYA1AsAYgWAMQrAEI1gAEawCCNQDBGoBgDUCwBiBYAxCsAQjWAARrAII1AMEagGANQLAGIFgDEKwBCNYABGsAgjUAwRqAYA1AsAYgWAMQrAEI1gAEawCCNQDBGoBgDUCwBiBYAxCsAQjWAARrAII1AMEagGANQLAGIFgDEKwBCNYABGsAgjUAwRqAYA1AsAYgWAMQrAEI1gAEawCCNQDBGoBgDUCwBiBYAxCsAQjWAARrAII1AMEagGANQLAGIFgDEKwBCNYABGsAgjUAwRqAYA1AsAYgWAMQrAEI1gAEawCCNQDBGoBgDUCwBiBYAxCsAQjWAARrAII1AMEagGANQLAGIFgDEKwBCNYABGsAgjUAwRqAYA1AsAYgWAMQrAEI1gAEawCCNQDBGoBgDUCwBiBYAxCsAQjWAARrAII1AMEagGANQLAGIFgDEKwBCNYABGsAgjUAwRqAYA1AsAYgWAMQrAEI1gAEawCCNQDBGoBgDUCwBiBYAxCsAQjWAARrAII1AMEagGANQLAGIFgDEKwBCNYABGsAgjUAwRqAYA1AsAYgWAMQrAEI1gAEawCCNQDBGoBgDUCwBiBYAxCsAQjWAARrAII1AMEagGANQLAGIFgDEKwBCNYABGsAgjUAwRqAYA1AsAYgWAMQrAEI1gAEawCCNQDBGoBgDUCwBiBYAxCsAQjWAARrAII1AMEagGANQLAGIFgDEKwBCNYABGsAgjUAwRqAYA1AsAYgWAMQrAEI1gAEawCCNQDBGoBgDUCwBiBYAxCsAQjWAARrAII1AMEagGANQLAGIFgDEKwBCNYAhBc1ywSFdJESHwAAAABJRU5ErkJggg==\n"},"metadata":{}}],"source":["height = 250\n","width = 350\n","blank_canvas = np.zeros((height, width, 3), np.uint8)\n","blank_canvas[:,0:width] = (209,193,255)\n","cv2_imshow(blank_canvas)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"GvSg21CAOuCP","executionInfo":{"status":"ok","timestamp":1684557186489,"user_tz":-480,"elapsed":287,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}}},"outputs":[],"source":["from sklearn.datasets import fetch_lfw_people"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"xpc7w84oPDB5","executionInfo":{"status":"ok","timestamp":1684557248704,"user_tz":-480,"elapsed":291,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}}},"outputs":[],"source":["lfw_peoples = fetch_lfw_people(resize=0.8, min_faces_per_person=100)\n","names = lfw_peoples.target_names\n","images = lfw_peoples.images\n","y = lfw_peoples.target"]},{"cell_type":"code","source":["len(y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4KptWrmVb8rM","executionInfo":{"status":"ok","timestamp":1684557258742,"user_tz":-480,"elapsed":5,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"9e7adc66-760f-4d74-c8b2-e2ee6fe5594a"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1140"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["len(images)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6La2yJVJb-XE","executionInfo":{"status":"ok","timestamp":1684557265354,"user_tz":-480,"elapsed":340,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"cbeefe52-9cf6-4143-a015-ac77cdee9c37"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1140"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["len(names)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5lrpUWyqgUp5","executionInfo":{"status":"ok","timestamp":1684558407509,"user_tz":-480,"elapsed":306,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"96c31be0-d4f8-4188-9caa-e545639ca273"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnctXzyPgZlF","executionInfo":{"status":"ok","timestamp":1684558424513,"user_tz":-480,"elapsed":3,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"c39da70c-f7e6-4b52-8239-537b4089630e"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Colin Powell', 'Donald Rumsfeld', 'George W Bush',\n","       'Gerhard Schroeder', 'Tony Blair'], dtype='<U17')"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KDbEM9eDhsDJ"},"outputs":[],"source":["classes = {}\n","for idx, target in enumerate(y):\n","  name = names[target]\n","  if name in classes:\n","    classes[names[target]].append(idx)\n","  else:\n","    classes[names[target]] = [idx] "]},{"cell_type":"code","execution_count":14,"metadata":{"id":"cHQdnUTsRJQs","executionInfo":{"status":"ok","timestamp":1684559080244,"user_tz":-480,"elapsed":293,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}}},"outputs":[],"source":["def mock_card_generator(image, name):\n","  height, width = (250, 350)\n","  v, h = (60, 30)\n","  text_v, text_h = (120, 80)\n","  canvas = np.zeros((height, width, 3), np.uint8)\n","  canvas[:,0:width] = (209,193,255)\n","  canvas[v:v+image.shape[0], h:h+image.shape[1]] = image\n","  cv2.putText(canvas, \"Name\", (text_v, text_h), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, 2)\n","  cv2.putText(canvas, name.upper(), (text_v, text_h + 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 1, 2)\n","  return canvas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fVO2uFGSYsZm"},"outputs":[],"source":["def remove_empty_lines(text):\n","  return \"\".join([s for s in text.strip().splitlines(True) if s.strip()])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NY3xzS3hXhSz"},"outputs":[],"source":["def get_name_from_image(image):\n","  text = ocr.image_to_string(image)\n","  lines = remove_empty_lines(text).splitlines()\n","  for idx, line in enumerate(lines):\n","    if (line == \"Name\"):\n","      return lines[idx + 1]\n","  return \"No name found\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mAgjQBQLWh8e"},"outputs":[],"source":["def face_detection(image):\n","  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","  faces = cascade_classifier.detectMultiScale(gray, 1.05, 3)\n","  return faces"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6rsm7CaJz5to"},"outputs":[],"source":["def cropped(image, cropArea):\n","  x, y, w, h = cropArea\n","  return image[y:y+h, x:x+w]"]},{"cell_type":"code","source":["def remapped_facial_features_using_landmarks(image, landmarks):\n","  # cropped all the features first\n","  left_eye_roi = image[(landmarks.part(37).y - 10):(landmarks.part(41).y + 10), (landmarks.part(36).x - 10):(landmarks.part(39).x + 10)]\n","  right_eye_roi = image[(landmarks.part(43).y - 10):(landmarks.part(47).y + 10), (landmarks.part(42).x - 10):(landmarks.part(45).x + 10)]\n","  nose_roi = image[(landmarks.part(27).y - 10):(landmarks.part(33).y + 10), (landmarks.part(27).x - 10):(landmarks.part(33).x + 10)]\n","  mouth_roi = image[(landmarks.part(50).y - 10):(landmarks.part(57).y + 10), (landmarks.part(48).x - 10):(landmarks.part(54).x + 10)]\n","  # resize all features\n","  left_eye_roi = cv2.resize(left_eye_roi, (50, 50), interpolation=cv2.INTER_LINEAR)\n","  right_eye_roi = cv2.resize(right_eye_roi, (50, 50), interpolation=cv2.INTER_LINEAR)\n","  nose_roi = cv2.resize(nose_roi, (50, 50), interpolation=cv2.INTER_LINEAR)\n","  mouth_roi = cv2.resize(mouth_roi, (50, 50), interpolation=cv2.INTER_LINEAR)\n","  # concat features into single image\n","  concat_eyes = cv2.hconcat([left_eye_roi, right_eye_roi])\n","  concat_nose_mouth = cv2.hconcat([nose_roi, mouth_roi])\n","  remapped = cv2.vconcat([concat_eyes, concat_nose_mouth])\n","  return remapped"],"metadata":{"id":"xTK-cj6KUvEt"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mnZL1Vz6mmKr"},"outputs":[],"source":["def face_landmark_detector(image):\n","  dlib_face_detector = dlib.get_frontal_face_detector()\n","  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","  faces = dlib_face_detector(image)\n","  for face in faces:\n","    landmarks = landmarks_predictor(gray, face)\n","    return landmarks\n","  return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohhv9TJ6qCAo"},"outputs":[],"source":["def get_face_hog_features(image):\n","  IMG_HEIGHT = 256\n","  IMG_WIDTH = 128\n","  img_size = (IMG_WIDTH, IMG_HEIGHT)\n","  block_size = (64, 64)\n","  block_stride = (2, 2)\n","  cell_size = (8, 8)\n","  nbins = 9\n","  faces = face_detection(image)\n","  hog = cv2.HOGDescriptor(img_size, block_size, block_stride, cell_size, nbins)\n","  all_face_features = []\n","  for face in faces:\n","    x, y, w, h = face\n","    cropped = image[y:y+h, x:x+w]\n","    cropped = cv2.resize(cropped, img_size)\n","    gray = cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)\n","    feature = hog.compute(gray)\n","    all_face_features.append(feature)\n","  return all_face_features\n"]},{"cell_type":"code","source":["def get_hog_features(image):\n","  IMG_HEIGHT = 256\n","  IMG_WIDTH = 128\n","  image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_LINEAR)\n","  img_size = (IMG_WIDTH, IMG_HEIGHT)\n","  block_size = (64, 64)\n","  block_stride = (2, 2)\n","  cell_size = (8, 8)\n","  nbins = 9\n","  hog = cv2.HOGDescriptor(img_size, block_size, block_stride, cell_size, nbins)\n","  feature = hog.compute(image)\n","  return feature"],"metadata":{"id":"t227pJTCVLP8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpg5khsbVxhv"},"outputs":[],"source":["def hog_cosine_similarity(hog_one, hog_two):\n","  hog_one = hog_one / np.linalg.norm(hog_one)\n","  hog_two = hog_two / np.linalg.norm(hog_two)\n","  return np.inner(np.transpose(hog_one), np.transpose(hog_two))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dXX1L0g2rZfi"},"outputs":[],"source":["def resnet50_feature_extractor(image, **kwargs):\n","  image = cv2.resize(image, (224, 224))\n","  image = np.reshape(image, (1, 224, 224, 3))  # reshape to (batch_size, height, width, channels)\n","  model = applications.ResNet50(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_tensor=None,\n","    input_shape=None,\n","    pooling=None,\n","    **kwargs)\n","  x = Flatten()(model.output)\n","  feature_extractor = Model(\n","   inputs=model.inputs,\n","   outputs=x)\n","  return feature_extractor(image)"]},{"cell_type":"code","source":["def vgg16_feature_extractor(image, **kwargs):\n","  image = cv2.resize(image, (224, 224))\n","  image = np.reshape(image, (1, 224, 224, 3))  # reshape to (batch_size, height, width, channels)\n","  model = applications.VGG16(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_tensor=None,\n","    input_shape=None,\n","    pooling=None,\n","    **kwargs)\n","  x = Flatten()(model.output)\n","  feature_extractor = Model(\n","   inputs=model.inputs,\n","   outputs=x)\n","  return feature_extractor(image)"],"metadata":{"id":"R8_A6Q6L1Zch"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def vgg19_feature_extractor(image, **kwargs):\n","  image = cv2.resize(image, (224, 224))\n","  image = np.reshape(image, (1, 224, 224, 3))  # reshape to (batch_size, height, width, channels)\n","  model = applications.VGG19(\n","    include_top=False,\n","    weights=\"imagenet\",\n","    input_tensor=None,\n","    input_shape=None,\n","    pooling=None,\n","    **kwargs)\n","  x = Flatten()(model.output)\n","  feature_extractor = Model(\n","   inputs=model.inputs,\n","   outputs=x)\n","  return feature_extractor(image)"],"metadata":{"id":"Go6wICcN_5D5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def vggface_feature_extractor(image, **kwargs):\n","  model = VGGFace(\n","        model='vgg16',\n","        include_top=False,\n","        input_shape=(224, 224, 3))\n","  \n","  image = cv2.resize(image, (224, 224))\n","  image = np.reshape(image, (1, 224, 224, 3))\n","  vggface_features = model.layers[-1].output\n","  feature_extractor = Model(inputs=model.input, outputs=vggface_features)\n","  return feature_extractor(image)"],"metadata":{"id":"lPRP8hEEz6GV"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9urfYzql36nX"},"outputs":[],"source":["def calculate_euclidean_distance(vector1, vector2):\n","  return np.linalg.norm(vector1 - vector2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_joMgMzl5Oam"},"outputs":[],"source":["def calculate_cosine_similarity(vector1, vector2):\n","  dot_product = np.dot(vector1, vector2)\n","  norm_1 = vector1 / np.linalg.norm(vector1)\n","  norm_2 = vector2 / np.linalg.norm(vector2)\n","  return dot_product / (norm_1 * norm_2)"]},{"cell_type":"code","source":["def extract_face_features(faceImg):\n","  print(\"faceImg\")"],"metadata":{"id":"j2OL7_sVAU4w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def get_eigenface_features(face):\n"],"metadata":{"id":"BPxa8EkTQ6Cn"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7BYVChsSyKxi"},"outputs":[],"source":["# cls_features = {}\n","# iter = tqdm(classes)\n","# for cls in iter:\n","#   iter.set_postfix({\"current cls\": cls})\n","#   image_idx = classes[cls][0]\n","#   img = cv2.cvtColor(images[image_idx] * 255, cv2.COLOR_GRAY2BGR)\n","#   cls_features[cls] = np.squeeze(cnn_feature_extractor(img))"]},{"cell_type":"markdown","metadata":{"id":"JEA3dE423M4V"},"source":[]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1854,"status":"ok","timestamp":1684559184245,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"},"user_tz":-480},"id":"YENR7tdl664n","outputId":"cd4d0736-2d66-4c3a-c5d2-ebb67365cbf6"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1140/1140 [00:01<00:00, 767.75it/s]\n"]}],"source":["# genenate a bunch of mock_cards with LFW dataset\n","mock_cards = []\n","# iter = tqdm(enumerate(images))\n","for idx, target in tqdm(enumerate(y), total=len(y)):\n","  name = names[target]\n","  face = cv2.cvtColor(images[idx] * 255, cv2.COLOR_GRAY2BGR)\n","  mock_card = mock_card_generator(face, name)\n","  mock_cards.append(mock_card)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1257,"status":"ok","timestamp":1681182686978,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"},"user_tz":-480},"id":"dw0Ifaa2_tqc","outputId":"3384dbab-ef38-48ad-9c3a-6e110176eacc"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:01<00:00,  3.77it/s]\n"]}],"source":["# generate reference gallary\n","gallary_hog = {}\n","iter = tqdm(classes)\n","for cls in iter:\n","  image_idx = classes[cls][0]\n","  img = cv2.cvtColor(images[image_idx] * 255, cv2.COLOR_GRAY2BGR)\n","  mock = mock_card_generator(img, cls)\n","  gallary_hog[cls] = get_face_hog_features(mock)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":213018,"status":"ok","timestamp":1681182899990,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"},"user_tz":-480},"id":"LHAO1Gds6lPZ","outputId":"f97b45da-14b2-4673-fd64-757511613156"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1140/1140 [03:32<00:00,  5.36it/s]\n"]}],"source":["ground_y = []\n","# use HOG with cosian similarity\n","hog_features = []\n","for idx, card in tqdm(enumerate(mock_cards), total=len(mock_cards)):\n","  hogs = get_face_hog_features(card)\n","  # hogs = get_face_hog_features(mock_cards[idx])\n","  if len(hogs) == 0:\n","    continue\n","  hog = hogs[0]\n","  hog_features.append(hog)\n","  ground_y.append(y[idx])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34332,"status":"ok","timestamp":1681182934292,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"},"user_tz":-480},"id":"4W6rGyZ5-38l","outputId":"372555b3-47c5-4500-e372-4369202939ee"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1136/1136 [00:34<00:00, 33.18it/s]\n"]}],"source":["y_pred = np.array([])\n","# make predictions\n","for hog in tqdm(hog_features):\n","  scores = {}\n","  for key, value in gallary_hog.items():\n","    cos_sims = hog_cosine_similarity(hog, value)\n","    scores[key] = cos_sims\n","  pred = max(scores, key=scores.get)\n","  y_pred = np.append(y_pred, np.where(names == pred)[0][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1681182934293,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"},"user_tz":-480},"id":"INMcptTUc-Jy","outputId":"8aa1c932-5fe4-4a87-feef-e2d414fcab3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["HOG with Cosine Similary accuracy:  0.4647887323943662\n"]}],"source":["print(\"HOG with Cosine Similary accuracy: \", accuracy_score(y_pred, ground_y))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14637,"status":"ok","timestamp":1681182948900,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"},"user_tz":-480},"id":"TjWgdoATG1GU","outputId":"dff1ea9f-fadd-412d-e96f-dd0f2adbd997"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1136/1136 [00:14<00:00, 78.14it/s]\n"]}],"source":["# use HOG with euclidean distance\n","y_pred = np.array([])\n","# make predictions\n","for hog in tqdm(hog_features):\n","  scores = {}\n","  for key, value in gallary_hog.items():\n","    dist = calculate_euclidean_distance(hog, value)\n","    scores[key] = dist\n","  pred = min(scores, key=scores.get)\n","  y_pred = np.append(y_pred, np.where(names == pred)[0][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1681182948901,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"},"user_tz":-480},"id":"RCm8G2PUDjNi","outputId":"129866ff-ea48-4349-84aa-5df83393f643"},"outputs":[{"output_type":"stream","name":"stdout","text":["HOG with Euclidean Distance accuracy:  0.4647887323943662\n"]}],"source":["print(\"HOG with Euclidean Distance accuracy: \", accuracy_score(y_pred, ground_y))"]},{"cell_type":"code","source":[],"metadata":{"id":"qE_N3P40ZXDf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# clear memory\n","hog_features = []"],"metadata":{"id":"bQuJh4gTxePT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a0aBu66aEOT2","executionInfo":{"status":"ok","timestamp":1681186384678,"user_tz":-480,"elapsed":3435805,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"a040d8e6-0788-44b9-f43d-d0f6987bbcad"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/1140 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 1s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1140/1140 [57:15<00:00,  3.01s/it]\n"]}],"source":["ground_y = []\n","resnet50_features = []\n","for idx, card in tqdm(enumerate(mock_cards), total=len(mock_cards)):\n","  face_roi = face_detection(card)\n","  if (len(face_roi) == 0):\n","    continue\n","  feat = np.squeeze(resnet50_feature_extractor(cropped(card, face_roi[0])))\n","  resnet50_features.append(feat)\n","  ground_y.append(y[idx])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JH0pZ2Q4Uw9G","executionInfo":{"status":"ok","timestamp":1681186399929,"user_tz":-480,"elapsed":15277,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"2d450a9e-b67b-44a1-b75e-f75ae63a168c"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:14<00:00,  2.99s/it]\n"]}],"source":["# generate reference gallary\n","gallary_cnn = {}\n","iter = tqdm(classes)\n","for cls in iter:\n","  image_idx = classes[cls][0]\n","  img = cv2.cvtColor(images[image_idx] * 255, cv2.COLOR_GRAY2BGR)\n","  mock = mock_card_generator(img, cls)\n","  face_roi = face_detection(mock)[0]\n","  feat = np.squeeze(resnet50_feature_extractor(cropped(mock, face_roi)))\n","  gallary_cnn[cls] = feat"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T1xLMcgiUodG","executionInfo":{"status":"ok","timestamp":1681186399929,"user_tz":-480,"elapsed":35,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"425f432d-0bbd-43e5-c71b-112e96f5a823"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1136/1136 [00:00<00:00, 2417.91it/s]\n"]}],"source":["# use CNN with euclidean distance\n","y_pred = np.array([])\n","for cnn in tqdm(resnet50_features):\n","  scores = {}\n","  for key, value in gallary_cnn.items():\n","    dist = calculate_euclidean_distance(cnn, value)\n","    scores[key] = dist\n","  pred = min(scores, key=scores.get)\n","  y_pred = np.append(y_pred, np.where(names == pred)[0][0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NeljIvYOYgTl","executionInfo":{"status":"ok","timestamp":1681186399930,"user_tz":-480,"elapsed":30,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"9d5ade3c-e450-4ea7-ca6c-7790231a67b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet50-based feature extractor with euclidean distance:  0.5017605633802817\n"]}],"source":["print(\"ResNet50-based feature extractor with euclidean distance: \", accuracy_score(y_pred, ground_y))"]},{"cell_type":"code","source":["resnet50_features = []"],"metadata":{"id":"nDK19tjlz3Du"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gallary_cnn = {}\n","iter = tqdm(classes)\n","for cls in iter:\n","  image_idx = classes[cls][0]\n","  img = cv2.cvtColor(images[image_idx] * 255, cv2.COLOR_GRAY2BGR)\n","  mock = mock_card_generator(img, cls)\n","  face_roi = face_detection(mock)[0]\n","  feat = np.squeeze(vgg16_feature_extractor(cropped(mock, face_roi)))\n","  gallary_cnn[cls] = feat"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hzXan_GC3GVB","executionInfo":{"status":"ok","timestamp":1681186410886,"user_tz":-480,"elapsed":10982,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"6f598aa5-5b60-4562-e26b-08207b608209"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/5 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 1s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:09<00:00,  1.98s/it]\n"]}]},{"cell_type":"code","source":["ground_y = []\n","vgg16_features = []\n","for idx, card in tqdm(enumerate(mock_cards), total=len(mock_cards)):\n","  face_roi = face_detection(card)\n","  if (len(face_roi) == 0):\n","    continue\n","  feat = np.squeeze(vgg16_feature_extractor(cropped(card, face_roi[0])))\n","  vgg16_features.append(feat)\n","  ground_y.append(y[idx])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oME2hvP13hlL","executionInfo":{"status":"ok","timestamp":1681187876009,"user_tz":-480,"elapsed":1465149,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"3a2e4262-afd5-4a7c-bc83-d9952c8252e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1140/1140 [24:25<00:00,  1.29s/it]\n"]}]},{"cell_type":"code","source":["# use VGG16 with euclidean distance\n","y_pred = np.array([])\n","# make predictions\n","for feat in tqdm(vgg16_features):\n","  scores = {}\n","  for key, value in gallary_cnn.items():\n","    dist = calculate_euclidean_distance(feat, value)\n","    scores[key] = dist\n","  pred = min(scores, key=scores.get)\n","  y_pred = np.append(y_pred, np.where(names == pred)[0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vr0QiwhQ5CSa","executionInfo":{"status":"ok","timestamp":1681187876010,"user_tz":-480,"elapsed":40,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"a95daaca-0ef8-43ea-9ea6-094c282e3453"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1136/1136 [00:00<00:00, 8940.88it/s]\n"]}]},{"cell_type":"code","source":["print(\"VGG16-based feature extractor with euclidean distance: \", accuracy_score(y_pred, ground_y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2TKTqYNn3xex","executionInfo":{"status":"ok","timestamp":1681187876010,"user_tz":-480,"elapsed":31,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"2ce3a343-e287-4c2b-f986-7a99d5099763"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VGG16-based feature extractor with euclidean distance:  0.3617957746478873\n"]}]},{"cell_type":"code","source":["vgg16_features = []"],"metadata":{"id":"FEkbRcnN_juP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gallary_cnn = {}\n","iter = tqdm(classes)\n","for cls in iter:\n","  image_idx = classes[cls][0]\n","  img = cv2.cvtColor(images[image_idx] * 255, cv2.COLOR_GRAY2BGR)\n","  mock = mock_card_generator(img, cls)\n","  face_roi = face_detection(mock)[0]\n","  feat = np.squeeze(vgg19_feature_extractor(cropped(mock, face_roi)))\n","  gallary_cnn[cls] = feat"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KjXQ8-7eACnW","executionInfo":{"status":"ok","timestamp":1681187885938,"user_tz":-480,"elapsed":9954,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"c794523f-345a-4a20-d9e0-44b31a55c164"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/5 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80134624/80134624 [==============================] - 1s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:09<00:00,  1.95s/it]\n"]}]},{"cell_type":"code","source":["ground_y = []\n","vgg19_features = []\n","for idx, card in tqdm(enumerate(mock_cards), total=len(mock_cards)):\n","  face_roi = face_detection(card)\n","  if (len(face_roi) == 0):\n","    continue\n","  feat = np.squeeze(vgg19_feature_extractor(cropped(card, face_roi[0])))\n","  vgg19_features.append(feat)\n","  ground_y.append(y[idx])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ixrG4O7AETU","executionInfo":{"status":"ok","timestamp":1681189719736,"user_tz":-480,"elapsed":1833828,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"81aaddbc-0bc3-43a1-f16a-f7649ab1e5c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1140/1140 [30:33<00:00,  1.61s/it]\n"]}]},{"cell_type":"code","source":["# use VGG19 with euclidean distance\n","y_pred = np.array([])\n","# make predictions\n","for feat in tqdm(vgg19_features):\n","  scores = {}\n","  for key, value in gallary_cnn.items():\n","    dist = calculate_euclidean_distance(feat, value)\n","    scores[key] = dist\n","  pred = min(scores, key=scores.get)\n","  y_pred = np.append(y_pred, np.where(names == pred)[0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1nUABUsAK-0","executionInfo":{"status":"ok","timestamp":1681189719737,"user_tz":-480,"elapsed":36,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"2dca1139-fbb3-4443-b7bc-ef1cd9745d43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1136/1136 [00:00<00:00, 8527.65it/s]\n"]}]},{"cell_type":"code","source":["print(\"VGG19-based feature extractor with euclidean distance: \", accuracy_score(y_pred, ground_y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8fivfiXZANzA","executionInfo":{"status":"ok","timestamp":1681189719737,"user_tz":-480,"elapsed":31,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"e3bec2b0-4500-4c81-d3df-8e07174d8c12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VGG19-based feature extractor with euclidean distance:  0.3160211267605634\n"]}]},{"cell_type":"code","source":["vgg19_features = []"],"metadata":{"id":"E8klatZCKlLl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gallary_cnn = {}\n","iter = tqdm(classes)\n","for cls in iter:\n","  image_idx = classes[cls][0]\n","  img = cv2.cvtColor(images[image_idx] * 255, cv2.COLOR_GRAY2BGR)\n","  mock = mock_card_generator(img, cls)\n","  face_roi = face_detection(mock)[0]\n","  feat = np.squeeze(vggface_feature_extractor(cropped(mock, face_roi)))\n","  gallary_cnn[cls] = feat"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DMOMgFoJ6Hw","executionInfo":{"status":"ok","timestamp":1681189727815,"user_tz":-480,"elapsed":8105,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"b1f77f67-8128-4dc4-d3f1-4798781f1bbf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/5 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5\n","58909280/58909280 [==============================] - 0s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:07<00:00,  1.59s/it]\n"]}]},{"cell_type":"code","source":["ground_y = []\n","vggface_features = []\n","for idx, card in tqdm(enumerate(mock_cards), total=len(mock_cards)):\n","  face_roi = face_detection(card)\n","  if (len(face_roi) == 0):\n","    continue\n","  feat = np.squeeze(vggface_feature_extractor(cropped(card, face_roi[0])))\n","  vggface_features.append(feat)\n","  ground_y.append(y[idx])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OxqgPmmiKiu7","executionInfo":{"status":"ok","timestamp":1681191055751,"user_tz":-480,"elapsed":1327962,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"951679a0-778f-47d5-f90e-05404ea34ba3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1140/1140 [22:07<00:00,  1.16s/it]\n"]}]},{"cell_type":"code","source":["# use VGGFace with euclidean distance\n","y_pred = np.array([])\n","# make predictions\n","for feat in tqdm(vggface_features):\n","  scores = {}\n","  for key, value in gallary_cnn.items():\n","    dist = calculate_euclidean_distance(feat, value)\n","    scores[key] = dist\n","  pred = min(scores, key=scores.get)\n","  y_pred = np.append(y_pred, np.where(names == pred)[0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XZ78bcaKKvZB","executionInfo":{"status":"ok","timestamp":1681191055752,"user_tz":-480,"elapsed":16,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"3ac9ba18-a54c-4081-a616-c82720231228"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1136/1136 [00:00<00:00, 8520.10it/s]\n"]}]},{"cell_type":"code","source":["print(\"VGGFace-based feature extractor with euclidean distance: \", accuracy_score(y_pred, ground_y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Sr4gD9qKy21","executionInfo":{"status":"ok","timestamp":1681191055753,"user_tz":-480,"elapsed":12,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"acd908f6-a34e-42df-dc12-5ec7558a2b74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VGGFace-based feature extractor with euclidean distance:  0.6690140845070423\n"]}]},{"cell_type":"markdown","source":["Here I attempt to improve the accuracy by remapping the facial features"],"metadata":{"id":"EIaNyNG2Y6IF"}},{"cell_type":"code","source":["# generate reference gallary\n","gallary_hog = {}\n","iter = tqdm(classes)\n","for cls in iter:\n","  image_idx = classes[cls][0]\n","  img = cv2.cvtColor(images[image_idx] * 255, cv2.COLOR_GRAY2BGR)\n","  mock = mock_card_generator(img, cls)\n","  landmarks = face_landmark_detector(mock)\n","  remapped = remapped_facial_features_using_landmarks(mock, landmarks)\n","  gallary_hog[cls] = get_hog_features(remapped)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EppuhmAUTdK0","executionInfo":{"status":"ok","timestamp":1681192043461,"user_tz":-480,"elapsed":3692,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"31f446a2-403f-4a52-860f-527665121c5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:03<00:00,  1.63it/s]\n"]}]},{"cell_type":"code","source":["remapped_faces = []\n","ground_y = []\n","# for idx, card in tqdm(enumerate(mock_cards), total=len(mock_cards)):\n","for idx in tqdm(range(500)):\n","  # landmarks = face_landmark_detector(card)\n","  landmakrs = face_landmark_detector(mock_cards[idx])\n","  if landmarks == None or landmarks.num_parts == 0:\n","    continue\n","  remapped = remapped_facial_features_using_landmarks(mock_cards[idx], landmarks)\n","  remapped_faces.append(remapped)\n","  ground_y.append(y[idx])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfqjHkCpZTdm","executionInfo":{"status":"ok","timestamp":1681195794542,"user_tz":-480,"elapsed":292502,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"ad32ed03-453a-4da9-af14-add7e0b78291"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [04:51<00:00,  1.71it/s]\n"]}]},{"cell_type":"code","source":["mock_cards = [] # clear memory"],"metadata":{"id":"kX_U0NsgbCtR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# use HOG with cosian similarity\n","hog_features = []\n","for remapped in tqdm(remapped_faces):\n","  hog = get_hog_features(remapped)\n","  hog_features.append(hog)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kK9k-CWYUhYH","executionInfo":{"status":"ok","timestamp":1681192377069,"user_tz":-480,"elapsed":60510,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"8ecb26c6-2cde-4e3d-9c51-4395e496ddcd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [01:00<00:00,  8.27it/s]\n"]}]},{"cell_type":"code","source":["y_pred = np.array([])\n","# make predictions\n","for hog in tqdm(hog_features):\n","  scores = {}\n","  for key, value in gallary_hog.items():\n","    cos_sims = hog_cosine_similarity(hog, value)\n","    scores[key] = cos_sims\n","  pred = max(scores, key=scores.get)\n","  y_pred = np.append(y_pred, np.where(names == pred)[0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UNji0-dOWaZP","executionInfo":{"status":"ok","timestamp":1681192392185,"user_tz":-480,"elapsed":15147,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"0e0ab149-dc53-4f5a-ce18-832df6174e8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:14<00:00, 33.52it/s]\n"]}]},{"cell_type":"code","source":["print(\"HOG with Cosine Similary accuracy: \", accuracy_score(y_pred, ground_y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"usqFA8QOWbrw","executionInfo":{"status":"ok","timestamp":1681192392185,"user_tz":-480,"elapsed":32,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"d7a47cf6-30a6-4ccd-b2c9-144508b892e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["HOG with Cosine Similary accuracy:  0.418\n"]}]},{"cell_type":"code","source":["# clear memory\n","hog_features = []"],"metadata":{"id":"tlRd0Sx9fXMS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generate reference gallary\n","gallary_cnn = {}\n","iter = tqdm(classes)\n","for cls in iter:\n","  image_idx = classes[cls][0]\n","  img = cv2.cvtColor(images[image_idx] * 255, cv2.COLOR_GRAY2BGR)\n","  mock = mock_card_generator(img, cls)\n","  landmarks = face_landmark_detector(mock)\n","  remapped = remapped_facial_features_using_landmarks(mock, landmarks)\n","  feat = np.squeeze(resnet50_feature_extractor(remapped))\n","  gallary_cnn[cls] = feat"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KWbcLaxUfycI","executionInfo":{"status":"ok","timestamp":1681192421992,"user_tz":-480,"elapsed":29833,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"bb88c3fe-9750-4d09-fe69-6ad92a2071ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:29<00:00,  5.96s/it]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C2ZP4A1zPHIR","executionInfo":{"status":"ok","timestamp":1681193886824,"user_tz":-480,"elapsed":1464858,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d275494b-c399-4859-e836-9ab859fa214c"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [24:24<00:00,  2.93s/it]\n"]}],"source":["resnet50_features = []\n","for img in tqdm(remapped_faces):\n","  feat = np.squeeze(resnet50_feature_extractor(img))\n","  resnet50_features.append(feat)"]},{"cell_type":"code","source":["# use CNN with euclidean distance\n","y_pred = np.array([])\n","for cnn in tqdm(resnet50_features):\n","  scores = {}\n","  for key, value in gallary_cnn.items():\n","    dist = calculate_euclidean_distance(cnn, value)\n","    scores[key] = dist\n","  pred = min(scores, key=scores.get)\n","  y_pred = np.append(y_pred, np.where(names == pred)[0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WSdoIlZXgbrr","executionInfo":{"status":"ok","timestamp":1681193886825,"user_tz":-480,"elapsed":34,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"7272c2d8-b770-4734-803d-7258e4375984"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:00<00:00, 1989.58it/s]\n"]}]},{"cell_type":"code","source":["print(\"ResNet50-based feature extractor with euclidean distance: \", accuracy_score(y_pred, ground_y))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GnU0FzALfs_2","executionInfo":{"status":"ok","timestamp":1681193886825,"user_tz":-480,"elapsed":28,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"02191221-2450-46ec-940e-763b7cde6108"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet50-based feature extractor with euclidean distance:  0.28\n"]}]},{"cell_type":"code","source":["resnet50_features = []"],"metadata":{"id":"eYjeDt7dtZNa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generate reference gallary\n","gallary_cnn = {}\n","iter = tqdm(classes)\n","for cls in iter:\n","  image_idx = classes[cls][0]\n","  img = cv2.cvtColor(images[image_idx] * 255, cv2.COLOR_GRAY2BGR)\n","  mock = mock_card_generator(img, cls)\n","  landmarks = face_landmark_detector(mock)\n","  remapped = remapped_facial_features_using_landmarks(mock, landmarks)\n","  feat = np.squeeze(vggface_feature_extractor(remapped))\n","  gallary_cnn[cls] = feat"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kbKcAwLd-f1Z","executionInfo":{"status":"ok","timestamp":1681195803811,"user_tz":-480,"elapsed":9296,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"bb86fbe3-89ef-4ea5-b997-80b34d9f80bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5/5 [00:09<00:00,  1.84s/it]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jSM10CxGBaLz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681196346821,"user_tz":-480,"elapsed":543040,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"b6e9e56b-fdb3-4796-cd2b-0612f20b8893"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [09:03<00:00,  1.09s/it]\n"]}],"source":["vggface_features = []\n","for img in tqdm(remapped_faces):\n","  feat = np.squeeze(vggface_feature_extractor(img))\n","  vggface_features.append(feat)"]},{"cell_type":"code","source":["# use VGGFace with euclidean distance\n","y_pred = np.array([])\n","# make predictions\n","for feat in tqdm(vggface_features):\n","  scores = {}\n","  for key, value in gallary_cnn.items():\n","    dist = calculate_euclidean_distance(feat, value)\n","    scores[key] = dist\n","  pred = min(scores, key=scores.get)\n","  y_pred = np.append(y_pred, np.where(names == pred)[0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95oeuQ9O-POP","executionInfo":{"status":"ok","timestamp":1681196346822,"user_tz":-480,"elapsed":35,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"e39cd40f-4644-4b87-f76e-20b0de03a375"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:00<00:00, 7459.94it/s]\n"]}]},{"cell_type":"code","source":["print(\"VGGFace-based feature extractor with euclidean distance: \", accuracy_score(y_pred, ground_y[:500]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xff0ceqM-Py9","executionInfo":{"status":"ok","timestamp":1681196346822,"user_tz":-480,"elapsed":32,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"16710044-8e52-42ad-e77f-3848b14637a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["VGGFace-based feature extractor with euclidean distance:  0.29\n"]}]},{"cell_type":"code","source":["# Train a siamease network\n","import tensorflow as tf\n","from keras.layers import Input, Conv2D, Flatten, Dense, Lambda, Subtract\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from sklearn.datasets import fetch_lfw_pairs\n","import numpy as np\n","\n","# Load the LFW dataset\n","lfw_pairs = fetch_lfw_pairs(subset='train', color=False)\n","\n","# Get the image pairs and labels\n","pairs_train = lfw_pairs.pairs\n","y_train = lfw_pairs.target\n","\n","# Extract the images from the pairs and preprocess the data\n","x_train = np.zeros((len(pairs_train), 2, 62, 47, 1), dtype=np.float32)\n","for i, pair in enumerate(pairs_train):\n","    x_train[i, 0] = (pair[0] / 255.0).reshape((62, 47, 1))\n","    x_train[i, 1] = (pair[1] / 255.0).reshape((62, 47, 1))\n","\n","# Split the dataset into anchor and positive pairs\n","x_anchor_train = x_train[:, 0]\n","x_positive_train = x_train[:, 1]\n","\n","# Get the negative pairs\n","x_negative_train = []\n","for i in range(len(x_anchor_train)):\n","    idx = np.random.choice(np.where(y_train != y_train[i])[0])\n","    x_negative_train.append(x_train[idx, 0])\n","x_negative_train = np.array(x_negative_train)\n","\n","# Combine the anchor, positive, and negative pairs into input pairs\n","input_pairs_train = [x_anchor_train, x_positive_train, x_negative_train]\n","\n","# Define the architecture of the Siamese network\n","input_shape = (62, 47, 1)\n","input_anchor = Input(shape=input_shape, name='anchor')\n","input_positive = Input(shape=input_shape, name='positive')\n","input_negative = Input(shape=input_shape, name='negative')\n","\n","conv1 = Conv2D(16, 3, activation='relu', padding='same')\n","conv2 = Conv2D(16, 3, activation='relu', padding='same')\n","pool1 = MaxPooling2D((2,2), padding='same')\n","flatten = Flatten()\n","dense1 = Dense(50, activation='relu')\n","\n","def siamese_dataset(pairs, labels, batch_size):\n","    dataset = tf.data.Dataset.from_tensor_slices((pairs, labels))\n","    dataset = dataset.shuffle(buffer_size=len(pairs))\n","    dataset = dataset.repeat()\n","    dataset = dataset.batch(batch_size)\n","    dataset = dataset.map(lambda x, y: ((x[:, 0], x[:, 1]), y))  # Return a tuple of two elements\n","    return dataset\n","\n","# Define the Siamese network as a model with two inputs and one output\n","input_shape = (62, 47, 1)\n","input_anchor = Input(shape=input_shape, name='anchor')\n","input_positive = Input(shape=input_shape, name='positive')\n","\n","conv1 = Conv2D(32, (3,3), activation='relu', padding='same')\n","pool1 = MaxPooling2D((2,2), padding='same')\n","conv2 = Conv2D(64, (3,3), activation='relu', padding='same')\n","pool2 = MaxPooling2D((2,2), padding='same')\n","flatten = Flatten()\n","dense1 = Dense(128, activation='relu')\n","\n","def siamese_network(inputs):\n","    x = conv1(inputs)\n","    x = conv2(x)\n","    x = pool1(x)\n","    x = flatten(x)\n","    x = dense1(x)\n","    return x\n","\n","encoded_anchor = siamese_network(input_anchor)\n","encoded_positive = siamese_network(input_positive)\n","\n","# Define the similarity measure between the outputs of the Siamese network\n","def L1_distance(x):\n","    return tf.abs(x[0] - x[1])\n","\n","positive_distance = Lambda(L1_distance)([encoded_anchor, encoded_positive])\n","\n","# Define the final output of the Siamese network\n","output = Dense(1, activation='sigmoid')(positive_distance)\n","\n","# Define the Siamese network as a model with two inputs and one output\n","model = Model(inputs=[input_anchor, input_positive], outputs=output)\n","\n","# Compile the model with the contrastive loss function and Adam optimizer\n","margin = 1\n","def contrastive_loss(y_true, y_pred):\n","    y_true = tf.cast(y_true, tf.float32)\n","    return tf.reduce_mean(y_true * tf.square(y_pred) + (1 - y_true) * tf.square(tf.maximum(margin - y_pred, 0)))\n","\n","model.compile(loss=contrastive_loss, optimizer=Adam(lr=0.0001))\n","\n","# Train the Siamese network on the LFW dataset\n","batch_size = 32\n","num_epochs = 20\n","train_dataset = siamese_dataset(x_train, y_train, batch_size)\n","steps_per_epoch = len(x_train) // batch_size\n","history = model.fit(train_dataset, steps_per_epoch=steps_per_epoch, epochs=num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"O1ShIiCZnrEV","executionInfo":{"status":"error","timestamp":1681193906148,"user_tz":-480,"elapsed":18272,"user":{"displayName":"Chang Siang Lim","userId":"07946584033098289435"}},"outputId":"ad84a8a0-6fef-4471-81ab-704e54c3d612"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-104fce6022ee>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mdense1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'MaxPooling2D' is not defined"]}]},{"cell_type":"code","source":["# Load the LFW dataset\n","lfw_pairs_test = fetch_lfw_pairs(subset='test', color=False)\n","\n","# Get the image pairs and labels\n","pairs_test = lfw_pairs_test.pairs\n","y_test = lfw_pairs_test.target\n","\n","# # Extract the images from the pairs and preprocess the data\n","# x_test = np.zeros((len(pairs_test), 2, 62, 47), dtype=np.float32)\n","# for i, pair in enumerate(pairs_test):\n","#     x_test[i, 0] = (pair[0] / 255.0).reshape((62, 47, 1))\n","#     x_test[i, 1] = (pair[1] / 255.0).reshape((62, 47, 1))\n","\n","# Split the dataset into anchor and positive pairs\n","x_anchor_test = x_test[:, 0]\n","x_positive_test = x_test[:, 1]\n","\n","# Get the negative pairs\n","x_negative_test = []\n","for i in range(len(x_anchor_test)):\n","    idx = np.random.choice(np.where(y_test != y_test[i])[0])\n","    x_negative_test.append(x_test[idx, 0])\n","x_negative_test = np.array(x_negative_test)\n","\n","# Combine the anchor, positive, and negative pairs into input pairs\n","input_pairs_test = [x_anchor_test, x_positive_test]\n","\n","# Compute the predicted similarity scores for the test set\n","y_pred = model.predict(input_pairs_test)\n","\n","# Threshold the scores to obtain binary predictions\n","y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n","\n","# Compute accuracy\n","accuracy = np.mean(y_pred_binary == y_test)\n","print('Accuracy:', accuracy)\n"],"metadata":{"id":"ayj5Eqr62EBd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_shape"],"metadata":{"id":"xEroXeo_xnS5"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO+dLQA9B4Fut6+pX1DH3ZN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"TPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}